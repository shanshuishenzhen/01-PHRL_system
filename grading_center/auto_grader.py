# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨é˜…å·ç³»ç»Ÿ

è´Ÿè´£è‡ªåŠ¨æ‰¹æ”¹å®¢è§‚é¢˜ï¼Œå¤„ç†ä¸»è§‚é¢˜ï¼Œç”Ÿæˆé˜…å·ç»“æœã€‚

æ›´æ–°æ—¥å¿—ï¼š
- 2025-01-07ï¼šåˆ›å»ºè‡ªåŠ¨é˜…å·ç³»ç»Ÿ
"""

import os
import sys
import json
import sqlite3
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any

# å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.append(str(Path(__file__).parent.parent))
from common.logger import get_logger
from common.error_handler import handle_error, retry
from common.sql_security import ParameterizedQuery


class AutoGrader:
    """è‡ªåŠ¨é˜…å·å™¨"""
    
    def __init__(self):
        self.logger = get_logger("auto_grader")
        self.queue_dir = Path(__file__).parent / "queue"
        self.graded_dir = Path(__file__).parent / "graded"
        self.processed_dir = Path(__file__).parent / "processed"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.queue_dir.mkdir(exist_ok=True)
        self.graded_dir.mkdir(exist_ok=True)
        self.processed_dir.mkdir(exist_ok=True)
    
    def process_pending_exams(self) -> int:
        """å¤„ç†å¾…é˜…å·çš„è€ƒè¯•"""
        processed_count = 0
        
        try:
            # è·å–é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰å¾…å¤„ç†æ–‡ä»¶
            pending_files = list(self.queue_dir.glob("*.json"))
            
            if not pending_files:
                self.logger.info("æ²¡æœ‰å¾…å¤„ç†çš„è€ƒè¯•ç»“æœ")
                return 0
            
            self.logger.info(f"å‘ç° {len(pending_files)} ä¸ªå¾…å¤„ç†çš„è€ƒè¯•ç»“æœ")
            
            for file_path in pending_files:
                try:
                    success = self.grade_single_exam(file_path)
                    if success:
                        processed_count += 1
                        # ç§»åŠ¨åˆ°å·²å¤„ç†ç›®å½•
                        processed_file = self.processed_dir / file_path.name
                        file_path.rename(processed_file)
                        self.logger.info(f"è€ƒè¯•ç»“æœå¤„ç†å®Œæˆ: {file_path.name}")
                    else:
                        self.logger.error(f"è€ƒè¯•ç»“æœå¤„ç†å¤±è´¥: {file_path.name}")
                        
                except Exception as e:
                    self.logger.error(f"å¤„ç†è€ƒè¯•æ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")
            
            return processed_count
            
        except Exception as e:
            self.logger.error(f"å¤„ç†å¾…é˜…å·è€ƒè¯•å¤±è´¥: {e}")
            return processed_count
    
    def grade_single_exam(self, file_path: Path) -> bool:
        """é˜…å·å•ä¸ªè€ƒè¯•"""
        try:
            # è¯»å–è€ƒè¯•ç»“æœ
            with open(file_path, 'r', encoding='utf-8') as f:
                exam_result = json.load(f)
            
            exam_id = exam_result.get('exam_id')
            user_id = exam_result.get('user_id')
            answers = exam_result.get('answers', {})
            
            self.logger.info(f"å¼€å§‹é˜…å·: è€ƒè¯•ID={exam_id}, ç”¨æˆ·ID={user_id}")
            
            # è·å–è€ƒè¯•çš„æ­£ç¡®ç­”æ¡ˆ
            correct_answers = self.get_correct_answers(exam_id)
            if not correct_answers:
                self.logger.warning(f"æ— æ³•è·å–è€ƒè¯• {exam_id} çš„æ­£ç¡®ç­”æ¡ˆï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†")
                return self.create_default_grading_result(exam_result, file_path)
            
            # è¿›è¡Œè‡ªåŠ¨é˜…å·
            grading_result = self.auto_grade_answers(answers, correct_answers)
            
            # ç”Ÿæˆæœ€ç»ˆé˜…å·ç»“æœ
            final_result = {
                "exam_id": exam_id,
                "user_id": user_id,
                "user_name": exam_result.get('user_name', ''),
                "username": exam_result.get('username', ''),
                "department": exam_result.get('department', ''),
                "paper_title": correct_answers.get('paper_title', ''),
                "submit_time": exam_result.get('submit_time'),
                "grading_time": datetime.now().isoformat(),
                "total_score": correct_answers.get('total_score', 100),
                "obtained_score": grading_result['total_obtained_score'],
                "final_score": grading_result['total_obtained_score'],
                "percentage": round((grading_result['total_obtained_score'] / correct_answers.get('total_score', 100)) * 100, 2),
                "question_scores": grading_result['question_scores'],
                "grading_details": grading_result['grading_details'],
                "auto_graded": True,
                "grader": "auto_grader_v1.0"
            }
            
            # ä¿å­˜é˜…å·ç»“æœ
            graded_file = self.graded_dir / f"graded_{exam_id}_{user_id}_{int(time.time())}.json"
            with open(graded_file, 'w', encoding='utf-8') as f:
                json.dump(final_result, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"é˜…å·å®Œæˆ: {graded_file.name}, å¾—åˆ†: {final_result['final_score']}/{final_result['total_score']}")
            return True
            
        except Exception as e:
            self.logger.error(f"é˜…å·å¤±è´¥: {e}")
            return False
    
    def get_correct_answers(self, exam_id) -> Optional[Dict]:
        """è·å–è€ƒè¯•çš„æ­£ç¡®ç­”æ¡ˆ"""
        try:
            # å°è¯•ä»é¢˜åº“æ•°æ®åº“è·å–æ­£ç¡®ç­”æ¡ˆ
            paper_id = self.extract_paper_id(exam_id)
            if paper_id:
                return self.get_answers_from_question_bank(paper_id)
            
            # å¦‚æœæ— æ³•ä»é¢˜åº“è·å–ï¼Œå°è¯•ä»è€ƒè¯•ç®¡ç†æ•°æ®è·å–
            return self.get_answers_from_exam_data(exam_id)
            
        except Exception as e:
            self.logger.error(f"è·å–æ­£ç¡®ç­”æ¡ˆå¤±è´¥: {e}")
            return None
    
    def extract_paper_id(self, exam_id) -> Optional[int]:
        """ä»exam_idæå–paper_id"""
        try:
            if isinstance(exam_id, str) and exam_id.startswith("exam_"):
                parts = exam_id.split("_")
                if len(parts) >= 2:
                    return int(parts[1])
            elif isinstance(exam_id, (int, str)) and str(exam_id).isdigit():
                return int(exam_id)
        except:
            pass
        return None
    
    def get_answers_from_question_bank(self, paper_id: int) -> Optional[Dict]:
        """ä»é¢˜åº“æ•°æ®åº“è·å–æ­£ç¡®ç­”æ¡ˆ"""
        try:
            db_path = Path(__file__).parent.parent / "question_bank_web" / "local_dev.db"
            if not db_path.exists():
                return None
            
            conn = sqlite3.connect(str(db_path))
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            # è·å–è¯•å·ä¿¡æ¯
            cursor.execute("""
                SELECT title, total_score, time_limit
                FROM papers 
                WHERE id = ?
            """, (paper_id,))
            
            paper = cursor.fetchone()
            if not paper:
                conn.close()
                return None
            
            # è·å–é¢˜ç›®å’Œç­”æ¡ˆ
            cursor.execute("""
                SELECT q.id, q.content, q.question_type, q.correct_answer, 
                       q.score, pq.question_order
                FROM questions q
                JOIN paper_questions pq ON q.id = pq.question_id
                WHERE pq.paper_id = ?
                ORDER BY pq.question_order
            """, (paper_id,))
            
            questions = cursor.fetchall()
            conn.close()
            
            if not questions:
                return None
            
            # æ„å»ºç­”æ¡ˆå­—å…¸
            correct_answers = {
                "paper_id": paper_id,
                "paper_title": paper['title'],
                "total_score": paper['total_score'] or 100,
                "questions": {}
            }
            
            for q in questions:
                question_id = str(q['id'])
                correct_answers["questions"][question_id] = {
                    "correct_answer": q['correct_answer'],
                    "question_type": q['question_type'],
                    "score": q['score'] or 10,
                    "content": q['content']
                }
            
            return correct_answers
            
        except Exception as e:
            self.logger.error(f"ä»é¢˜åº“è·å–ç­”æ¡ˆå¤±è´¥: {e}")
            return None
    
    def get_answers_from_exam_data(self, exam_id) -> Optional[Dict]:
        """ä»è€ƒè¯•æ•°æ®è·å–ç­”æ¡ˆï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°ä»å…¶ä»–æ•°æ®æºè·å–ç­”æ¡ˆçš„é€»è¾‘
            # æš‚æ—¶è¿”å›Noneï¼Œä½¿ç”¨é»˜è®¤è¯„åˆ†
            return None
        except Exception as e:
            self.logger.error(f"ä»è€ƒè¯•æ•°æ®è·å–ç­”æ¡ˆå¤±è´¥: {e}")
            return None
    
    def auto_grade_answers(self, student_answers: Dict, correct_answers: Dict) -> Dict:
        """è‡ªåŠ¨é˜…å·"""
        question_scores = []
        grading_details = []
        total_obtained_score = 0
        
        questions = correct_answers.get("questions", {})
        
        for question_id, correct_data in questions.items():
            student_answer = student_answers.get(question_id, "")
            correct_answer = correct_data.get("correct_answer", "")
            question_type = correct_data.get("question_type", "")
            max_score = correct_data.get("score", 10)
            
            # æ ¹æ®é¢˜ç›®ç±»å‹è¿›è¡Œè¯„åˆ†
            obtained_score = self.grade_question(
                student_answer, correct_answer, question_type, max_score
            )
            
            question_scores.append({
                "question_id": question_id,
                "max_score": max_score,
                "obtained_score": obtained_score,
                "student_answer": student_answer,
                "correct_answer": correct_answer,
                "question_type": question_type
            })
            
            grading_details.append({
                "question_id": question_id,
                "content": correct_data.get("content", ""),
                "student_answer": student_answer,
                "correct_answer": correct_answer,
                "score": f"{obtained_score}/{max_score}",
                "is_correct": obtained_score == max_score
            })
            
            total_obtained_score += obtained_score
        
        return {
            "total_obtained_score": total_obtained_score,
            "question_scores": question_scores,
            "grading_details": grading_details
        }
    
    def grade_question(self, student_answer: Any, correct_answer: Any, 
                      question_type: str, max_score: float) -> float:
        """è¯„åˆ†å•ä¸ªé¢˜ç›®"""
        try:
            if question_type == "single_choice":
                return max_score if str(student_answer).strip() == str(correct_answer).strip() else 0
            
            elif question_type == "multiple_choice":
                # å¤šé€‰é¢˜éœ€è¦å®Œå…¨åŒ¹é…
                if isinstance(student_answer, list) and isinstance(correct_answer, list):
                    student_set = set(str(x).strip() for x in student_answer)
                    correct_set = set(str(x).strip() for x in correct_answer)
                    return max_score if student_set == correct_set else 0
                else:
                    return max_score if str(student_answer).strip() == str(correct_answer).strip() else 0
            
            elif question_type == "true_false":
                # åˆ¤æ–­é¢˜
                student_bool = str(student_answer).lower() in ['true', '1', 'yes', 'æ˜¯', 'å¯¹', 'æ­£ç¡®']
                correct_bool = str(correct_answer).lower() in ['true', '1', 'yes', 'æ˜¯', 'å¯¹', 'æ­£ç¡®']
                return max_score if student_bool == correct_bool else 0
            
            elif question_type == "fill_blank":
                # å¡«ç©ºé¢˜ï¼Œç®€å•å­—ç¬¦ä¸²åŒ¹é…
                student_text = str(student_answer).strip().lower()
                correct_text = str(correct_answer).strip().lower()
                return max_score if student_text == correct_text else 0
            
            elif question_type == "essay":
                # ç®€ç­”é¢˜ï¼Œæš‚æ—¶ç»™ä¸€åŠåˆ†æ•°ï¼ˆéœ€è¦äººå·¥é˜…å·ï¼‰
                if str(student_answer).strip():
                    return max_score * 0.5  # ç»™50%çš„åˆ†æ•°
                else:
                    return 0
            
            else:
                # æœªçŸ¥é¢˜å‹ï¼Œç»™ä¸€åŠåˆ†æ•°
                return max_score * 0.5 if str(student_answer).strip() else 0
                
        except Exception as e:
            self.logger.error(f"è¯„åˆ†é¢˜ç›®å¤±è´¥: {e}")
            return 0
    
    def create_default_grading_result(self, exam_result: Dict, file_path: Path) -> bool:
        """åˆ›å»ºé»˜è®¤é˜…å·ç»“æœï¼ˆå½“æ— æ³•è·å–æ­£ç¡®ç­”æ¡ˆæ—¶ï¼‰"""
        try:
            answers = exam_result.get('answers', {})
            total_questions = len(answers)
            
            # ç»™æ¯é¢˜10åˆ†ï¼Œç­”é¢˜ç»™5åˆ†ï¼Œæœªç­”é¢˜ç»™0åˆ†
            question_scores = []
            total_obtained_score = 0
            
            for i, (question_id, answer) in enumerate(answers.items(), 1):
                score = 5 if str(answer).strip() else 0
                question_scores.append({
                    "question_id": question_id,
                    "max_score": 10,
                    "obtained_score": score,
                    "student_answer": answer,
                    "correct_answer": "æœªçŸ¥",
                    "question_type": "unknown"
                })
                total_obtained_score += score
            
            # ç”Ÿæˆé»˜è®¤ç»“æœ
            final_result = {
                "exam_id": exam_result.get('exam_id'),
                "user_id": exam_result.get('user_id'),
                "user_name": exam_result.get('user_name', ''),
                "username": exam_result.get('username', ''),
                "department": exam_result.get('department', ''),
                "paper_title": "é»˜è®¤è¯„åˆ†è¯•å·",
                "submit_time": exam_result.get('submit_time'),
                "grading_time": datetime.now().isoformat(),
                "total_score": total_questions * 10,
                "obtained_score": total_obtained_score,
                "final_score": total_obtained_score,
                "percentage": round((total_obtained_score / (total_questions * 10)) * 100, 2) if total_questions > 0 else 0,
                "question_scores": question_scores,
                "grading_details": [],
                "auto_graded": True,
                "grader": "default_grader",
                "note": "ä½¿ç”¨é»˜è®¤è¯„åˆ†è§„åˆ™ï¼šç­”é¢˜å¾—5åˆ†ï¼Œæœªç­”é¢˜å¾—0åˆ†"
            }
            
            # ä¿å­˜ç»“æœ
            graded_file = self.graded_dir / f"default_graded_{exam_result.get('exam_id')}_{exam_result.get('user_id')}_{int(time.time())}.json"
            with open(graded_file, 'w', encoding='utf-8') as f:
                json.dump(final_result, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"é»˜è®¤é˜…å·å®Œæˆ: {graded_file.name}")
            return True
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºé»˜è®¤é˜…å·ç»“æœå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    grader = AutoGrader()
    
    print("ğŸ¯ å¯åŠ¨è‡ªåŠ¨é˜…å·ç³»ç»Ÿ...")
    processed_count = grader.process_pending_exams()
    
    if processed_count > 0:
        print(f"âœ… æˆåŠŸå¤„ç† {processed_count} ä¸ªè€ƒè¯•ç»“æœ")
    else:
        print("â„¹ï¸ æ²¡æœ‰å¾…å¤„ç†çš„è€ƒè¯•ç»“æœ")


if __name__ == "__main__":
    main()
